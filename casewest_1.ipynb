{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1suV5Kv8Z6KHrU6BWIh5DYb3iSQJ6pakj",
      "authorship_tag": "ABX9TyMzBuRP2tzxu74Jcc+sZpVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naldo14/tesis-/blob/main/casewest_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Np7gtRCdbSBE"
      },
      "outputs": [],
      "source": [
        "import h5py #librerua para crear archivos , h5py\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy import signal    #aqui estoy usando la libreria signal\n",
        "import scipy.io\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hacer el mounted de mi cuenta drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfLVDq7beZFp",
        "outputId": "21dabfd4-e752-4abb-bc45-817fc5aacb38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#celda para crear la lista con los paths de mi data\n",
        "paths=[] #creo la lista de pahts\n",
        "names=[] #creo la lista de nombres\n",
        "output_file=[]\n",
        "paths.append('/content/drive/MyDrive/tesis USB /case west reserve university')\n",
        "names.append('casewest')\n",
        "output_file.append('/content/drive/MyDrive/tesis USB /case west reserve university/data')"
      ],
      "metadata": {
        "id": "qClZds_Yed5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hago el unar del archivo\n",
        "!pip install rarfile\n",
        "\n",
        "from google.colab import drive\n",
        "import rarfile\n",
        "\n",
        "# Path to the .zip file in Google Drive\n",
        "zip_file_path = paths[0]+'/'+names[0]+\".rar\"\n",
        "\n",
        "with rarfile.RarFile(zip_file_path, 'r') as rf:\n",
        "    rf.extractall(output_file[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2opzPJuftNi",
        "outputId": "5ea5e83d-29de-4e4e-84a0-e3878f549621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo que los h5py file vacios\n",
        "import os\n",
        "import h5py\n",
        "\n",
        "# List of directory paths\n",
        "directory_paths = [\n",
        "    \"/content/drive/MyDrive/tesis USB /case west reserve university/data/inner\",\n",
        "    \"/content/drive/MyDrive/tesis USB /case west reserve university/data/outter\",\n",
        "    \"/content/drive/MyDrive/tesis USB /case west reserve university/data/outter1\",\n",
        "    \"/content/drive/MyDrive/tesis USB /case west reserve university/data/normal\"\n",
        "]\n",
        "\n",
        "# Loop through each directory path\n",
        "for directory_path in directory_paths:\n",
        "    # Get the directory name (e.g., \"inner,\" \"outter,\" etc.)\n",
        "    directory_name = os.path.basename(directory_path)\n",
        "\n",
        "    # Create an h5py file for the directory\n",
        "    h5py_file = h5py.File(f\"{directory_name}.h5\", \"w\")\n",
        "\n",
        "    # List .mat files in the directory\n",
        "    mat_files = [f for f in os.listdir(directory_path) if f.endswith(\".mat\")]\n",
        "\n",
        "    # Add each .mat file to the h5py file as an empty dataset\n",
        "    for mat_file in mat_files:\n",
        "        # Create an empty dataset\n",
        "        dataset = h5py_file.create_dataset(mat_file, shape=(0,), dtype='f4')\n",
        "\n",
        "    # Close the h5py file\n",
        "    h5py_file.close()\n",
        "\n",
        "# Now you have separate h5py files for each directory with empty datasets"
      ],
      "metadata": {
        "id": "_BuWOWrPnzgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#guardo los archivos . mat en los archivos h5py\n",
        "# Define the h5py file name you want to inspect\n",
        "h5py_file_name = \"/content/drive/MyDrive/tesis USB /case west reserve university/inner.h5\"\n",
        "mat_files_directory='/content/drive/MyDrive/tesis USB /case west reserve university/data/inner'\n",
        "\n",
        "# Open the h5py file\n",
        "with h5py.File(h5py_file_name, 'w') as h5file:\n",
        "    # Get the keys (dataset names) in the h5py file\n",
        "    mat_files = [f for f in os.listdir(mat_files_directory) if f.endswith(\".mat\")]\n",
        "\n",
        "    # Add each .mat file content to the h5py file\n",
        "    for mat_file in mat_files:\n",
        "        # Load the .mat file\n",
        "        mat_data = scipy.io.loadmat(os.path.join(mat_files_directory, mat_file))\n",
        "\n",
        "        # Create datasets for each variable in the .mat file\n",
        "        for var_name, var_data in mat_data.items():\n",
        "            h5file.create_dataset(f\"{mat_file}/{var_name}\", data=var_data)\n"
      ],
      "metadata": {
        "id": "FalpDU-vqxNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### function to storaged all the .mat file into the h5py's file\n",
        "def save_mat_to_h5py(mat_files_directories, h5py_file_names):\n",
        "    if len(mat_files_directories) != len(h5py_file_names):\n",
        "        print(\"Error: The number of directories and h5py file names should match.\")\n",
        "        return\n",
        "\n",
        "    for mat_files_directory, h5py_file_name in zip(mat_files_directories, h5py_file_names):\n",
        "        # Open the h5py file\n",
        "        with h5py.File(h5py_file_name, 'w') as h5file:\n",
        "            # Get the list of .mat files in the directory\n",
        "            mat_files = [f for f in os.listdir(mat_files_directory) if f.endswith(\".mat\")]\n",
        "\n",
        "            # Add each .mat file content to the h5py file\n",
        "            for mat_file in mat_files:\n",
        "                # Load the ..mat file\n",
        "                mat_data = scipy.io.loadmat(os.path.join(mat_files_directory, mat_file))\n",
        "\n",
        "                # Create datasets for each variable in the .mat file\n",
        "                for var_name, var_data in mat_data.items():\n",
        "                    h5file.create_dataset(f\"{mat_file}/{var_name}\", data=var_data)\n",
        "\n",
        "mat_files_directories = [\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/data/inner',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/data/normal',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/data/outter',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/data/outter1'\n",
        "\n",
        "]\n",
        "h5py_file_names = [\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/inner.h5',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/normal.h5',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/outter.h5',\n",
        "    '/content/drive/MyDrive/tesis USB /case west reserve university/outter1.h5'\n",
        "]\n",
        "save_mat_to_h5py(mat_files_directories, h5py_file_names)"
      ],
      "metadata": {
        "id": "HObiN8sZ6bx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_1=\"/content/drive/MyDrive/tesis USB /case west reserve university/outter1.h5\"\n",
        "# Open the h5py file\n",
        "with h5py.File(file_1, 'r') as h5file:\n",
        "    # List the keys (dataset names) in the h5py file\n",
        "    keys = list(h5file.keys())\n",
        "\n",
        "    # Choose a specific .mat file (dataset) by its key\n",
        "    target_mat_file = keys[1]  # Change this to the key you want to inspect\n",
        "\n",
        "    # Access the content of the chosen .mat file\n",
        "    mat_data = h5file[target_mat_file]\n",
        "\n",
        "    # Create a dictionary to store the arrays\n",
        "    arrays = {}\n",
        "\n",
        "    for key, value in mat_data.items():\n",
        "        if isinstance(value, h5py.Group):\n",
        "            # If it's a group (nested data), you can access its keys\n",
        "            subkeys = list(value.keys())\n",
        "            for subkey in subkeys:\n",
        "                # Access the actual data (arrays) and store in the dictionary\n",
        "                subkey_data = value[subkey][()]\n",
        "                arrays[subkey] = subkey_data\n",
        "        else:\n",
        "            # If it's a dataset (e.g., a variable), you can access its value\n",
        "            # and store it in the dictionary using the original key\n",
        "            variable_data = value[()]\n",
        "            arrays[key] = variable_data\n",
        "\n",
        "# Now, you have a dictionary 'arrays' where the keys are the array names\n",
        "# and the values are the corresponding arrays from the .mat file"
      ],
      "metadata": {
        "id": "OLnre0YssXYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def band_maker(coeffs, fs, title):\n",
        "    p = len(coeffs)- 1\n",
        "    low_frequencies = [None] * len(coeffs)\n",
        "    high_frequencies = [None] * len(coeffs)\n",
        "\n",
        "    # low_frequencies[0] = 0\n",
        "    # high_frequencies[0] = fs / (2 ** (p) * 2)\n",
        "    for i in range(0, len(coeffs)):\n",
        "         high_frequencies[i] = fs / (2 ** (p+-i + 1))\n",
        "    low_frequencies[0]=0\n",
        "    low_frequencies[1:len(low_frequencies)]= high_frequencies[:len(low_frequencies) - 1]\n",
        "\n",
        "\n",
        "\n",
        "    return  high_frequencies,low_frequencies"
      ],
      "metadata": {
        "id": "6IgxjkfiEd-w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frequencies_maker(N,fs,d,D,theta):\n",
        "  theta=(theta/180)*np.pi\n",
        "  FTF=(fs/2)*(1-d/D*np.cos(theta))\n",
        "  BPFI=(N*fs/2)*(1+d/D*np.cos(theta))\n",
        "  BPFO=(N*fs/2)*(1-d/D*np.cos(theta))\n",
        "  BSF=(D*fs/d)*(1-(d/D)**2*np.cos(theta))\n",
        "  return(FTF,BPFI,BPFO,BSF)\n"
      ],
      "metadata": {
        "id": "S2jaHAMsEiEP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FTF,BPFI,BPFO,BSF=frequencies_maker(9,50.17,7.90,38.5,0) #estos datos son para el daata set coreano\n",
        "data = {\n",
        "    'Name': ['Fundamental train frequency (FTF)', 'Ball pass frequency inner (BPFI)', 'Ball pass frequency outer (BPFO)','Ball spin frequency (BSF)'],\n",
        "    'Values (HZ)': [FTF, BPFI, BPFO,BSF]\n",
        "}\n",
        "\n",
        "# Create a dataframe from the dictionary\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfIjXas3Eo1O",
        "outputId": "978c18c6-7248-4e9a-d18e-55b4ba74afd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Name  Values (HZ)\n",
            "0  Fundamental train frequency (FTF)    19.937688\n",
            "1   Ball pass frequency inner (BPFI)   272.090805\n",
            "2   Ball pass frequency outer (BPFO)   179.439195\n",
            "3          Ball spin frequency (BSF)   234.204744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'data' now contains a dictionary where the keys are the .mat file names\n",
        "# and the values are dictionaries containing the arrays for each .mat file\n",
        "\n",
        "def get_h5py_data(h5py_file_path):\n",
        "    data = {}\n",
        "\n",
        "    # Open the h5py file\n",
        "    with h5py.File(h5py_file_path, 'r') as h5file:\n",
        "        # List the keys (dataset names) in the h5py file\n",
        "        keys = list(h5file.keys())\n",
        "\n",
        "        for key in keys:\n",
        "            # Access the content of the .mat file (dataset)\n",
        "            mat_data = h5file[key]\n",
        "\n",
        "            # Create a dictionary to store the arrays for this .mat file\n",
        "            arrays = {}\n",
        "\n",
        "            for subkey, value in mat_data.items():\n",
        "                if isinstance(value, h5py.Group):\n",
        "                    # If it's a group (nested data), you can access its keys\n",
        "                    subkeys = list(value.keys())\n",
        "                    for subkey in subkeys:\n",
        "                        # Access the actual data (arrays) and store in the dictionary\n",
        "                        subkey_data = value[subkey][()]\n",
        "                        arrays[subkey] = subkey_data\n",
        "                else:\n",
        "                    # If it's a dataset (e.g., a variable), you can access its value\n",
        "                    # and store it in the dictionary using the original key\n",
        "                    variable_data = value[()]\n",
        "                    arrays[subkey] = variable_data\n",
        "\n",
        "            # Store the arrays for this .mat file in the data dictionary\n",
        "            data[key] = arrays\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "09aiBY-PA6Nk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## almacenamiento de la data inner\n",
        "file_path = \"/content/drive/MyDrive/tesis USB /case west reserve university/outter1.h5\"\n",
        "data_inner = get_h5py_data(file_path)"
      ],
      "metadata": {
        "id": "scVPx_mPBebJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## almacenamiento de la data outter\n",
        "file_path = \"/content/drive/MyDrive/tesis USB /case west reserve university/outter.h5\"\n",
        "data_outter = get_h5py_data(file_path)"
      ],
      "metadata": {
        "id": "YhK__C2TDyRb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## almacenamiento de la data outter\n",
        "file_path = \"/content/drive/MyDrive/tesis USB /case west reserve university/outter1.h5\"\n",
        "data_outter_1 = get_h5py_data(file_path)"
      ],
      "metadata": {
        "id": "S6n0oQOED3hZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## almacenamiento de la data normal\n",
        "file_path = \"/content/drive/MyDrive/tesis USB /case west reserve university/normal.h5\"\n",
        "data_normal = get_h5py_data(file_path)"
      ],
      "metadata": {
        "id": "Upuyyyi_D8cL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculo el nivel del banco de filtro:\n",
        "fs=math.ceil(FTF) #frecuencia natural , se usa la del train frequencie\n",
        "fe=25.6e3 # frecuencia de sampleo\n",
        "n = math.ceil(math.log(fe / fs) / math.log(2)) +2\n",
        "level = n"
      ],
      "metadata": {
        "id": "AYjEB684F0bM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4SqzO9GRGMF1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}